1. Test Strategy (Document Outline):
•	Architecture Understanding
o	Briefly summarize system components, flows, and tiering logic (SSD, HDD, Object Storage; policies and file movement rules).
•	Testing Types to Cover
o	Unit testing: Individual API input/output.
o	Integration testing: API interactions and tiering results.
o	System/end-to-end: Multi-step flows, real user scenarios.
o	Performance: Stress tiering, upload/download large files.
o	Security: Access control, data exposure, permissions.
•	Sample Test Scenarios
o	Edge cases: Min/max file size, file accessed right before 30/90 days, simultaneous uploads/deletes.
o	Policy testing: Moved files after 30/90 days, up-tier movement (cold to warm/hot).
o	API errors: Invalid requests (wrong fileId, improper formats).
o	Fault injection: Tiering process interruptions/restarts.
•	Test Data
o	Files: Various sizes/boundary values, random and sequential access patterns.
o	Metadata: Manipulated lastAccessed timestamps for policy coverage.
o	Users: (if authentication present) different permission levels.
•	Rationale
o	Map how tests ensure business logic, reliability, and scalability.
________________________________________
2. Test Implementation (Code):
•	Organize in Suites
o	Test files per endpoint (e.g., test_file_upload.py, test_tiering.py).
•	Sample Implementation Approach (Python, requests, pytest)
Python code implementation	

import requests

def test_file_upload():
    resp = requests.post("http://localhost:8000/files", files={"file": open("test.bin", "rb")})
    assert resp.status_code == 200
    assert resp.json()["tier"] == "HOT"

def test_manual_tiering():
    resp = requests.post("http://localhost:8000/admin/tiering/run")
    assert resp.status_code == 200
    assert "filesMoved" in resp.json()
•	Include cases for:
o	File uploads (valid/invalid sizes)
o	Downloads
o	Metadata correctness after access/tiering
o	Tiering triggers and result validation
o	Error conditions (missing id, invalid upload)
o	Performance (upload/download high volume)
o	Security (try unauthorized operations)
o	Concurrent access (multi-threaded upload/download)
________________________________________
3. Bug Report:
•	Create a template:
o	Issue Summary
o	Steps to Reproduce
o	Expected vs Actual Behavior
o	Logs/Screenshots
o	Priority suggestion (Critical/High/Medium/Low)
•	Example:
text
Issue: File not moved to 'Warm' after 30 days inactivity
Steps: Upload file, set lastAccessed > 30 days ago, trigger tiering
Expected: File tier changes to 'Warm'
Actual: File remains in 'Hot'
Priority: High
Suggestion: Check tiering policy logic for lastAccessed calculation
________________________________________
Bonus Part (Implementation & CI/CD):
•	Feature Implementation:
o	Add file versioning (API: POST/GET /files/{fileId}/versions)
o	Bulk operations: Accept multiple files in requests.
o	Custom metadata: Extend POST /files with metadata fields.
•	Performance Improvements:
o	Index database for faster tiering.
o	Add paging parameters to metadata endpoints.
o	Use caching for stats queries.
•	Automated Testing & CI/CD:
o	Write test scripts for each endpoint and feature.
o	Use GitHub Actions YAML for automated test runs and reporting.
o	Add coverage report tools (pytest-cov).
o	README: Setup, test, run instructions.
________________________________________
Action Plan Summary
•	Start by drafting a Test Strategy document (Google Doc/Markdown).
•	Scaffold test code using Python (pytest recommended for API testing).
•	Log all bugs/issues in a separate bug report file.
•	Tackle bonus feature fixes and improvements after primary tests.
•	Automate test runs via GitHub Actions (yaml workflow example available).
Here’s a comprehensive test_script.py covering all major API endpoint scenarios and key edge/error cases for your Cloud Storage Tiering System. This example uses pytest and requests—suitable for local/system and CI/CD usage.
Python code implementation via Visual Studio Code
•	import pytest
•	import requests
•	import os
•	
•	BASE_URL = "http://localhost:8000"
•	TEST_FILE = "twomb.txt"  # Ensure this file exists and is about 2MB
•	
•	def log(msg):
•	    print(f"\n========================\n{msg}\n========================")
•	
•	def upload_file(file_path):
•	    log(f"STEP: Start Uploading file: {file_path}")
•	    with open(file_path, "rb") as f:
•	        files = {'file': (os.path.basename(file_path), f)}
•	        r = requests.post(f"{BASE_URL}/files", files=files)
•	    print(f"Upload request sent, status code: {r.status_code}")
•	    print(f"Upload response content: {r.text}")
•	    assert r.status_code == 200
•	    file_id = r.json()["fileId"]
•	    print(f"Uploaded successfully! Assigned file_id: {file_id}")
•	    log(f"STEP: End Upload for {file_path}")
•	    return file_id
•	
•	def test_file_upload_download_delete():
•	    log("TEST: File Upload-Download-Delete START")
•	    file_id = upload_file(TEST_FILE)
•	    
•	    log(f"STEP: Downloading file with id: {file_id}")
•	    r = requests.get(f"{BASE_URL}/files/{file_id}")
•	    print(f"Download request sent, status code: {r.status_code}")
•	    assert r.status_code == 200
•	    print("Download successful!")
•	
•	    log(f"STEP: Deleting file with id: {file_id}")
•	    r = requests.delete(f"{BASE_URL}/files/{file_id}")
•	    print(f"Delete request sent, status code: {r.status_code}")
•	    assert r.status_code == 204
•	    print("Delete successful!")
•	    log("TEST: File Upload-Download-Delete END")
•	
•	def test_metadata_after_upload():
•	    log("TEST: Metadata After Upload START")
•	    file_id = upload_file(TEST_FILE)
•	    log(f"STEP: Fetching metadata for file id: {file_id}")
•	    r = requests.get(f"{BASE_URL}/files/{file_id}/metadata")
•	    print(f"Metadata request sent, status code: {r.status_code}, response: {r.text}")
•	    assert r.status_code == 200
•	    meta = r.json()
•	    print(f"Metadata tier: {meta['tier']}, size: {meta['size']}")
•	    assert meta["tier"] == "HOT"
•	    assert meta["size"] >= 2*1024*1024  # 2MB
•	    print("Metadata checks passed!")
•	    log("TEST: Metadata After Upload END")
•	
•	def test_error_invalid_file_id():
•	    log("TEST: Error Invalid File ID START")
•	    print("Sending GET request with invalid file ID...")
•	    r = requests.get(f"{BASE_URL}/files/not_a_valid_id")
•	    print(f"Status code for invalid file ID: {r.status_code}")
•	    assert r.status_code in [400, 404]
•	    print("Invalid file ID error check passed!")
•	    log("TEST: Error Invalid File ID END")
•	
•	def test_get_stats():
•	    log("TEST: Get System Stats START")
•	    print("Sending GET request to fetch system stats...")
•	    r = requests.get(f"{BASE_URL}/admin/stats")
•	    print(f"Stats request sent, status code: {r.status_code}, content: {r.text}")
•	    assert r.status_code == 200
•	    stats = r.json()
•	    print(f"System stats keys: {list(stats.keys())}")
•	    assert "totalFiles" in stats
•	    assert "hotTier" in stats
•	    print("System stats checks passed!")
•	    log("TEST: Get System Stats END")
•	
•	def test_tiering_process():
•	    log("TEST: Manual Tiering Process START")
•	    file_id = upload_file(TEST_FILE)
•	    print("Triggering manual tiering process...")
•	    r = requests.post(f"{BASE_URL}/admin/tiering/run")
•	    print(f"Tiering trigger request sent, status code: {r.status_code}, response: {r.text}")
•	    r = requests.get(f"{BASE_URL}/files/{file_id}/metadata")
•	    meta = r.json()
•	    print(f"Metadata after tiering: tier={meta['tier']}")
•	    assert meta["tier"] in ["HOT", "WARM", "COLD"]
•	    print("Tiering process check passed!")
•	    log("TEST: Manual Tiering Process END")
•	
•	def test_concurrent_access():
•	    log("TEST: Concurrent Access START")
•	    import threading
•	    results = []
•	
•	    def upload_and_delete():
•	        try:
•	            file_id = upload_file(TEST_FILE)
•	            print(f"[Thread] Deleting file: {file_id}")
•	            r = requests.delete(f"{BASE_URL}/files/{file_id}")
•	            print(f"[Thread] Delete status: {r.status_code}")
•	            results.append(r.status_code == 204)
•	        except Exception as e:
•	            print(f"[Thread] Error: {e}")
•	            results.append(False)
•	
•	    threads = [threading.Thread(target=upload_and_delete) for _ in range(5)]
•	    for t in threads: t.start()
•	    for t in threads: t.join()
•	    print("Concurrent access test results:", results)
•	    assert all(results)
•	    print("Concurrent access test passed!")
•	    log("TEST: Concurrent Access END")
•	
•	if __name__ == "__main__":
•	    log("=== RUNNING ALL TEST CASES ===")
•	    pytest.main()
•	    log("=== TEST RUN COMPLETE ===")
•	
•	Notes:
All the uploaded script files use the local twomb.txt file as their input source
•	Adjust BASE_URL as per your service host/port.
•	The script uses basic APIs—extend for custom metadata, versioning, pagination, and bulk as bonus.
•	For failures and concurrency, this uses threads; for more stress, try multiprocessing or external test tools.
•	For performance tests, wrap uploads/downloads in timing blocks and assert response times.
Execution explanation :
Imports and Setup
•	import pytest, requests, os:
•	pytest: Used for automated testing and running test cases.
•	requests: Provides functions to make HTTP requests to your API.
•	os: Helps handle file paths.
Constants:
•	BASE_URL: Address of your API service.
•	TEST_FILE: The name of the file used for testing upload and other file operations.
________________________________________
Utility Function
log(msg)
Prints clear, separated log messages for easy step tracking.
________________________________________
Key Helper
upload_file(file_path)
Purpose:
Uploads a file to your storage API and returns the assigned file_id.
Process:
1.	Logs the start of upload.
2.	Opens the file in binary read mode.
3.	Sends a POST request to /files with the file as payload.
4.	Prints the HTTP status and response from API.
5.	Checks/asserts for success (status_code == 200).
6.	Logs success and extracts the assigned unique file_id from the response.
7.	Logs the end of upload and returns file_id for further use.
________________________________________
Test: File Upload-Download-Delete
test_file_upload_download_delete()
Purpose:
Checks the core file-handling workflow (upload, then download, then delete).
Step-by-step:
1.	Upload:
•	Calls upload_file(TEST_FILE) and gets a file_id.
•	Why? To ensure file upload works and provides a usable identifier.
2.	Download:
•	Logs download start.
•	Sends a GET to /files/{file_id}.
•	Prints status and checks for success (status_code == 200).
•	Why? To verify that uploaded files can be retrieved correctly.
3.	Delete:
•	Logs delete start.
•	Sends a DELETE to /files/{file_id}.
•	Prints result and asserts success (status_code == 204).
•	Why? To make sure files can be removed and cleanup is successful.
4.	Logs the end of the test.
________________________________________
Reasons for File Upload and Delete Steps:
•	File upload:
•	Confirms your service is accepting files as expected.
•	Generates a file_id that acts as a reference for all further actions (download, metadata, etc.).
•	Tests your API flow from client perspective.
•	File delete:
•	Ensures hitting the /files/{file_id} DELETE endpoint works.
•	Prevents stale test data, keeps the environment clean.
•	Validates that storage tiering and lifecycle policies will not be blocked by deletion issues.
•	Essential for data consistency and integrity tests.
________________________________________
Other Tests (Summary)
•	test_metadata_after_upload(): Uploads, then checks metadata correctness (tier, size).
•	test_error_invalid_file_id(): Verifies API returns proper error for invalid IDs.
•	test_get_stats(): Fetches system stats and asserts important keys exist.
•	test_tiering_process(): Uploads a file, triggers tiering, then checks for tier update.
•	test_concurrent_access(): Uses threading to test if multiple uploads/deletes can happen at once without errors.
________________________________________
Main Execution
Runs all test cases with visible start/end logs.
________________________________________
Summary Table for Upload/Delete Flow
Step	What it Does	Reason/Goal
Upload (upload_file)	Sends file to API, fetches file_id	Sets up subsequent operations; checks upload endpoint
Download	Retrieves uploaded file by file_id	Validates file retrieval from storage
Delete	Removes uploaded file by file_id	Checks cleanup, state management, and API correctness
In essence:
•	You upload so you can download, check metadata, and delete.
•	Each step is logged and validated for proper response and behavior.
•	This helps confirm your API is reliable and meets core requirements.

Test_Results:

PS C:\cloud_storage_sdet_assignment_main\src> & "C:/Program Files/Python310/python.exe" c:/cloud_storage_sdet_assignment_main/src/demo_test_script_3.py

========================
=== RUNNING ALL TEST CASES ===
========================
=========================================================== test session starts ===========================================================
platform win32 -- Python 3.10.11, pytest-9.0.0, pluggy-1.6.0
rootdir: C:\cloud_storage_sdet_assignment_main\src
collected 0 items                                                                                                                          

========================================================== no tests ran in 0.01s ========================================================== 

========================
=== TEST RUN COMPLETE ===
========================
PS C:\cloud_storage_sdet_assignment_main\src> & "C:/Program Files/Python310/python.exe" c:/cloud_storage_sdet_assignment_main/src/demo_test_script_3.py > C:\anil\test_log_for_demo_test_script_3.txt             
PS C:\cloud_storage_sdet_assignment_main\src> & "C:/Program Files/Python310/python.exe" c:/cloud_storage_sdet_assignment_main/src/demo_test_script_3.py

========================
=== RUNNING ALL TEST CASES ===
========================
=========================================================== test session starts ===========================================================
platform win32 -- Python 3.10.11, pytest-9.0.0, pluggy-1.6.0
rootdir: C:\cloud_storage_sdet_assignment_main\src
collected 0 items                                                                                                                           

========================================================== no tests ran in 0.01s ========================================================== 

========================
=== TEST RUN COMPLETE ===
========================

How to Report Bugs with Clarity
To report bugs clearly, always include the following details:
Bug Report Template
1. Title/Summary:
•	Short and specific description of the issue.
Example: “Manual tiering process does not update file tier after trigger.”
2. Environment:
•	Where did the bug occur? (e.g., API version, test environment, OS)
3. Steps to Reproduce:
•	Clear, step-by-step instructions.
Example:
1.	Upload a file with size 2MB.
2.	Change its lastAccessed date to 35 days ago.
3.	Call /admin/tiering/run.
4.	Fetch metadata for the file.
4. Expected Result:
•	What should happen?
Example:
“File tier should change from HOT to WARM.”
5. Actual Result:
•	What actually happened?
Example:
“File remains in HOT tier.”
6. Evidence:
•	Console logs, API responses, screenshots if available.
Example:
text
{ "fileId": "abc123", "tier": "HOT", "lastAccessed": "2024-09-01T00:00:00Z" }
7. Severity/Priority:
•	How serious is the bug? (e.g., Critical, High, Medium, Low)

________________________________________

Manual Tiering Does Not Update File Tier As Expected
Environment:
API v1.0, Localhost, Python 3.10, Windows 11
Steps to Reproduce:
1.	Upload a file of size 2MB.
2.	Manually 
3.	Call /admin/tiering/run.
4.	Get file metadata via /files/{fileId}/metadata.
Expected Result:
File should move from HOT to WARM tier.
Actual Result:
File remains in HOT tier.
Evidence:
API Response after tiering:
json
{"fileId": "abc123", "tier": "HOT", "lastAccessed": "2024-09-01T00:00:00Z"}
Severity:
High
Sample Fix/Improvement Statement
Fix:
Update the runTiering function to query files whose lastAccessed date is ≥ 30 days ago, and move them to the next appropriate tier.
Impact:
This ensures files are moved between storage tiers according to policy, maintaining system efficiency and integrity.
Proposed Improvement:
Implement logging for all tiering operations, so future failures can be diagnosed more easily and audits can be performed.

Here is the script below which I used was using the file from browser

import pytest
import requests
import random
import string
import io
from datetime import datetime, timedelta

BASE_URL = "http://localhost:8000"

def random_file(size):
    return io.BytesIO(bytearray(random.getrandbits(8) for _ in range(size)))

def upload_file(size=1024*1024, name="testfile.bin"):
    files = {'file': (name, random_file(size))}
    r = requests.post(f"{BASE_URL}/files", files=files)
    assert r.status_code == 200
    return r.json()["fileId"]

def test_file_upload_download_delete():
    file_id = upload_file()
    r = requests.get(f"{BASE_URL}/files/{file_id}")
    assert r.status_code == 200
    r = requests.delete(f"{BASE_URL}/files/{file_id}")
    assert r.status_code == 204

def test_metadata_after_upload():
    file_id = upload_file(size=2*1024*1024)
    r = requests.get(f"{BASE_URL}/files/{file_id}/metadata")
    assert r.status_code == 200
    meta = r.json()
    assert meta["tier"] == "HOT"
    assert meta["size"] >= 2*1024*1024

def test_upload_invalid_size():
    # Below min size
    files = {'file': ("small.bin", random_file(500 * 1024))}
    r = requests.post(f"{BASE_URL}/files", files=files)
    assert r.status_code == 400

    # Above max size
    files = {'file': ("big.bin", random_file(11*1024*1024*1024))}
    r = requests.post(f"{BASE_URL}/files", files=files)
    assert r.status_code == 400

def test_tiering_process():
    file_id = upload_file(name="tieringtest.bin")
    # Simulate lastAccessed > 30 days by API (or patch DB for a real system)
    # Here we assume API lets us set the metadata, otherwise this code won't move actual file
    requests.post(f"{BASE_URL}/admin/tiering/run")
    r = requests.get(f"{BASE_URL}/files/{file_id}/metadata")
    meta = r.json()
    assert meta["tier"] in ["HOT", "WARM", "COLD"]

def test_get_stats():
    r = requests.get(f"{BASE_URL}/admin/stats")
    assert r.status_code == 200
    stats = r.json()
    assert "totalFiles" in stats
    assert "hotTier" in stats

def test_concurrent_access():
    import threading
    results = []

    def upload_and_delete():
        try:
            file_id = upload_file()
            requests.delete(f"{BASE_URL}/files/{file_id}")
            results.append(True)
        except Exception:
            results.append(False)

    threads = [threading.Thread(target=upload_and_delete) for _ in range(10)]
    for t in threads: t.start()
    for t in threads: t.join()

    assert all(results)

def test_error_invalid_file_id():
    r = requests.get(f"{BASE_URL}/files/not_a_valid_id")
    assert r.status_code in [400, 404]

def test_bulk_operations():
    # If supported: For bonus implementation!
    pass

# For performance and fault injection, use fixtures or parametrize with timeouts/forced failures as needed.

if __name__ == "__main__":
    pytest.main()

please follow the the git link provided “https://github.com/Anilreddy250/lucidity_Assignment.git”
